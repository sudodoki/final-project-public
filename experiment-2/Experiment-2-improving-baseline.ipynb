{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Carry overs from previous notebook_\n",
    "    \n",
    "## Issues\n",
    "\n",
    "1. Annotated data having issues:\n",
    "  - (Fixed by sorting chars) different annotators possibly having different order in pairs\n",
    "  - (Fixed by dropping NR chars / affinity) NR still present with some comments\n",
    "2. Book sources having issues:\n",
    "  - different editions of same book might be available with different level of changes (starting with additions / deletions ending with non-rendering font using Æ and others)\n",
    "  - licensing need to be removed as it introduces extra noise\n",
    "3. book-nlp output having issues:\n",
    "  - as is, it causes issues when loaded via pandas as there're ocasionally a label for token that is too long or some other issues\n",
    "  - might result in same character being represented as multiple\n",
    "4. current algorithm having issues:\n",
    "  - no way to limit characters to only 'important once', so we can do some sort of validation but either external part should be responsible for selecting the main characters (and it's not yet fact those would be present in annotated relations) or current system updated to account for that\n",
    "  - sentiment of sentences mentioning two characters isn't the best way, some papers mention other ways of doing this\n",
    "\n",
    "## Next steps\n",
    "\n",
    "1. There are still long way to go with this amount of data and this baseline: tuning sentiment, removing stopwords, fixing all of the issues.\n",
    "2. I have another dataset that need some transforming to be compatible with current one\n",
    "3. Trying other baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections as col\n",
    "from sklearn import metrics\n",
    "\n",
    "import books_utils as bu\n",
    "import baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'baseline' from '/Users/sudodoki/Projects/AI_ML/projector-nlp/final-project-public/experiment-2/baseline.py'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in annotations / books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>change</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>character_1</th>\n",
       "      <th>character_2</th>\n",
       "      <th>affinity</th>\n",
       "      <th>coarse_category</th>\n",
       "      <th>fine_category</th>\n",
       "      <th>detail</th>\n",
       "      <th>book_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>49</td>\n",
       "      <td>1005</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>528</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>annotator_1</td>\n",
       "      <td>no</td>\n",
       "      <td>Timon of Athens</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Joseph K.</td>\n",
       "      <td>Timon</td>\n",
       "      <td>positive</td>\n",
       "      <td>social</td>\n",
       "      <td>friend</td>\n",
       "      <td>NR</td>\n",
       "      <td>Hamlet_William_Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>760</td>\n",
       "      <td>1712</td>\n",
       "      <td>20</td>\n",
       "      <td>613</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1120</td>\n",
       "      <td>886</td>\n",
       "      <td>342</td>\n",
       "      <td>1591</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          annotator change            title               author character_1  \\\n",
       "count          2137   2137             2137                 2137        2137   \n",
       "unique           14      3              109                   49        1005   \n",
       "top     annotator_1     no  Timon of Athens  William Shakespeare   Joseph K.   \n",
       "freq            760   1712               20                  613          15   \n",
       "\n",
       "       character_2  affinity coarse_category fine_category detail  \\\n",
       "count         2137      2137            2137          2137   2137   \n",
       "unique         825         3               4            30    528   \n",
       "top          Timon  positive          social        friend     NR   \n",
       "freq            17      1120             886           342   1591   \n",
       "\n",
       "                         book_name  \n",
       "count                         2137  \n",
       "unique                         109  \n",
       "top     Hamlet_William_Shakespeare  \n",
       "freq                            20  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv('../data/character_relation_annotations.txt.gz', sep='\\t')\n",
    "# dropping values that have gibberish affinity - might transform this later based on category\n",
    "annotations = annotations[(annotations['affinity'] != 'NR') & (annotations['character_1'] != 'NR') & (annotations['character_2'] != 'NR')].copy()\n",
    "annotations['book_name'] = (annotations['title'] + ' ' + annotations['author']).str.replace(\"\\s\", \"_\")\n",
    "print(annotations.shape)\n",
    "# making sure no NR in character_1/character_2/affinity\n",
    "annotations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working around multiple annotators giving different marks - transforming into\n",
    "# real value based on mapping and averaging it\n",
    "def avg(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "affinity_mapping = {\n",
    "    'positive': 1,\n",
    "    'neutral': 0.5,\n",
    "    'negative': 0\n",
    "}\n",
    "annotations['num_affinity'] = annotations['affinity'].map(lambda aff: affinity_mapping[aff])\n",
    "all_df = pd.DataFrame(columns=['book_name', 'char_1', 'char_2', 'affinity'])\n",
    "by_book_annotations = col.defaultdict(col.defaultdict)\n",
    "def add_books_annotations(row):\n",
    "    book_name = row['book_name']\n",
    "    char_1, char_2 = sorted([row['character_1'], row['character_2']])\n",
    "    affinity = row['num_affinity']\n",
    "    by_book_annotations[book_name][char_1 + ':' + char_2] = (by_book_annotations[book_name][char_1 + ':' + char_2] if (char_1 + ':' + char_2) in by_book_annotations[book_name] else []) + [affinity]\n",
    "\n",
    "annotations.apply(add_books_annotations, axis=1)\n",
    "\n",
    "for book in by_book_annotations:\n",
    "    for pair in by_book_annotations[book]:\n",
    "        [char_1, char_2] = pair.split(':')\n",
    "        all_df = all_df.append([{\n",
    "            'book_name': book, 'char_1': char_1, 'char_2': char_2, 'affinity': avg(by_book_annotations[book][pair])\n",
    "        }])\n",
    "# voila, afinnity as single column dataframe with real values and all_x having book_name, char_1 and char_2 names\n",
    "all_y = all_df['affinity'].copy()\n",
    "all_X = all_df.drop('affinity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 109, True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure all raw txt files are present for books\n",
    "titles = annotations['title'].unique()\n",
    "authors = [annotations[annotations['title'] == title]['author'][0:1].ravel()[0] for title in titles]\n",
    "existing_files = []\n",
    "names = []\n",
    "for pair in zip(titles, authors):\n",
    "    title, author = pair\n",
    "    name = re.sub(\"\\s\", \"_\", '{} {}'.format(title, author))\n",
    "    names.append(name)\n",
    "    file = '../data/books/{}.txt'.format(name)\n",
    "    existing_files.append(os.path.isfile(file))\n",
    "len(titles), len(existing_files), all(existing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [bu.Book(name, book_NLP_folder=\"../data/bookNLP_output\", source_folder=\"../data/books\") for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in books:\n",
    "    if len(book.tokens) < 100:\n",
    "        print(book.name, len(book.tokens), book.tokens.shape)\n",
    "# seems that most tokens are non-empty, yet issue with parsing the bookNLP token output into dataframes\n",
    "# underneath we are skipping those lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don Quixote | Don Quixotes\n",
      "Altisidora | ALTISIDORA\n",
      "Don Quixote | Senor Don Quixote\n",
      "Sampson Carrasco | SAMSON CARRASCO\n",
      "Don Quixote | lord Don Quixote\n",
      "Rocinante | Rocinante\n",
      "The Duke and Duchess | Duke of Sesa\n",
      "Cervantes | Miguel de Cervantes\n",
      "The Duke and Duchess | Duke Ricardo\n",
      "Cide Hamete Benengeli | Cide Hamete Benengeli\n",
      "Sancho Panza | Sancho Panzas\n",
      "Dapple | Dapple\n",
      "Sancho Panza | Senor Don Sancho Panza\n",
      "Dulcinea del Toboso | lady Dona Dulcinea del Toboso\n"
     ]
    }
   ],
   "source": [
    "book = books[0]\n",
    "book_name = book.name\n",
    "subset = all_X[all_X['book_name'] == book_name]\n",
    "present_chars = pd.concat([subset['char_1'], subset['char_2']]).unique()\n",
    "for char in book.characters.meaningful:\n",
    "    name = bu.book_name_to_annotated_name(book_name, char, present_chars, False)\n",
    "    if name:\n",
    "        print(name, \"|\", bu.longest_name(char))\n",
    "# Okay, new challenge - we need to 'merge' characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'baseline' from '/Users/sudodoki/Projects/AI_ML/projector-nlp/final-project-public/experiment-2/baseline.py'>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(bu)\n",
    "importlib.reload(baseline)\n",
    "importlib.reload(bu)\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books:   4%|▎         | 4/109 [01:06<29:42, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books:  30%|███       | 33/109 [04:43<10:18,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books:  49%|████▊     | 53/109 [07:15<03:45,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books:  51%|█████▏    | 56/109 [07:24<03:11,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books:  94%|█████████▍| 103/109 [5:24:28<2:17:09, 1371.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looping over books: 100%|██████████| 109/109 [5:24:54<00:00, 166.29s/it]   \n"
     ]
    }
   ],
   "source": [
    "base_predictor = baseline.create_for(books, all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_label(val):\n",
    "    if val <= 0.33:\n",
    "        return 'negative'\n",
    "    if val <= 0.66:\n",
    "        return 'neutral'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = baseline.predict(base_predictor, all_X)\n",
    "y_predicted.clip(0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18553792295085625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_predicted, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.35      0.08      0.13       397\n",
      "    neutral       0.22      0.86      0.35       312\n",
      "   positive       0.60      0.12      0.20       759\n",
      "\n",
      "avg / total       0.45      0.27      0.21      1468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(all_y.map(score_to_label), y_predicted.map(score_to_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3092465656221617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.00      0.00      0.00       397\n",
      "    neutral       0.00      0.00      0.00       312\n",
      "   positive       0.52      1.00      0.68       759\n",
      "\n",
      "avg / total       0.27      0.52      0.35      1468\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# one more baseline, just to check - major class\n",
    "y_all_positive = np.ones_like(y_predicted)\n",
    "print(metrics.mean_squared_error(y_all_positive, all_y))\n",
    "print(metrics.classification_report(all_y.map(score_to_label), [score_to_label(val) for val in y_all_positive]))\n",
    "# well, at least our baseline does something more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books issues with chars\n",
    "# WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
    "# WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
    "# WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
    "# WARNING: Mrs. Ned Hale might have multiple aliases: ['Mrs. Ned Hale', 'Ned Hale']\n",
    "# WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Sense_and_Sensibility_Jane_Austen 3 Mrs. John Dashwood\n",
      "32 The_Iliad_Homer 78 Hector son of Priam\n",
      "55 Great_Expectations_Charles_Dickens 92 Mrs. Joe Gargery\n",
      "70 Ethan_Frome_Edith_Wharton 6 Mrs. Ned Hale\n",
      "102 The_Mayor_of_Casterbridge_Thomas_Hardy 42 Elizabeth-Jane Newson\n"
     ]
    }
   ],
   "source": [
    "bad_chars = set([\"Mrs. John Dashwood\",\n",
    "\"Hector son of Priam\",\n",
    "\"Mrs. Joe Gargery\",\n",
    "\"Mrs. Joe Gargery\",\n",
    "\"Mrs. Ned Hale\",\n",
    "\"Elizabeth-Jane Newson\"])\n",
    "for (i,book) in enumerate(books):\n",
    "    for char in book.characters.meaningful:\n",
    "        if bu.longest_name(char) in bad_chars:\n",
    "            print(i, book.name, char['id'], bu.longest_name(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I identified these chars, I'm not sure what to do with all of this:\n",
    "\n",
    "1. Mrs. John Dashwood as identificator for wife of Mr. John Dashwood\n",
    "2. son of Priam mentioning Priam in no way refers to Priam himself\n",
    "3. Mrs. Joe Gargery as identificator for wife of Mr. Joe Gargery\n",
    "4. Not even sure about this one, but I think once again this is identificator for wife of Mr. Ned Hale\\\n",
    "5. Newson is used as reference to father of Elizabeth-Jane Newson\n",
    "\n",
    "so I'm considering adding following rules to bu.book_name_to_annotated_name()\n",
    "\n",
    "```\n",
    "Mrs. + Name != Name\n",
    "X son of Y != Y\n",
    "Firstname Lastname != Lastname\n",
    "```\n",
    "\n",
    "although first one could have another way of working out if we would have gender annotation for characters in dataset (given bookNLP infers gender), yet there are issues with bookNLP getting confused on its own with Mrs. John Dashwood (considering John Dashwood being same character and not Mr. John Dashwood who is character on his own)\n",
    "\n",
    "🤔 might be an issue for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
