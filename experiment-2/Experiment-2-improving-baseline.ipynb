{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Carry overs from previous notebook_\n",
    "    \n",
    "## Issues\n",
    "\n",
    "1. Annotated data having issues:\n",
    "  - (Fixed by sorting chars) different annotators possibly having different order in pairs\n",
    "  - (Fixed by dropping NR chars / affinity) NR still present with some comments\n",
    "2. Book sources having issues:\n",
    "  - different editions of same book might be available with different level of changes (starting with additions / deletions ending with non-rendering font using Æ and others)\n",
    "  - licensing need to be removed as it introduces extra noise\n",
    "3. book-nlp output having issues:\n",
    "  - (Fixed by quote attr) as is, it causes issues when loaded via pandas as there're ocasionally a label for token that is too long or some other issues\n",
    "  - might result in same character being represented as multiple\n",
    "4. current algorithm having issues:\n",
    "  - no way to limit characters to only 'important once', so we can do some sort of validation but either external part should be responsible for selecting the main characters (and it's not yet fact those would be present in annotated relations) or current system updated to account for that\n",
    "  - sentiment of sentences mentioning two characters isn't the best way, some papers mention other ways of doing this\n",
    "\n",
    "## Next steps\n",
    "\n",
    "1. There are still long way to go with this amount of data and this baseline: tuning sentiment, removing stopwords, fixing all of the issues.\n",
    "2. I have another dataset that need some transforming to be compatible with current one\n",
    "3. Trying other baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import collections as col\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import books_utils as bu\n",
    "import baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in annotations / books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>change</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>character_1</th>\n",
       "      <th>character_2</th>\n",
       "      <th>affinity</th>\n",
       "      <th>coarse_category</th>\n",
       "      <th>fine_category</th>\n",
       "      <th>detail</th>\n",
       "      <th>book_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>49</td>\n",
       "      <td>1005</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>528</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>annotator_1</td>\n",
       "      <td>no</td>\n",
       "      <td>The Return of the Native</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Joseph K.</td>\n",
       "      <td>Timon</td>\n",
       "      <td>positive</td>\n",
       "      <td>social</td>\n",
       "      <td>friend</td>\n",
       "      <td>NR</td>\n",
       "      <td>Dracula_Bram_Stoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>760</td>\n",
       "      <td>1712</td>\n",
       "      <td>20</td>\n",
       "      <td>613</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1120</td>\n",
       "      <td>886</td>\n",
       "      <td>342</td>\n",
       "      <td>1591</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          annotator change                     title               author  \\\n",
       "count          2137   2137                      2137                 2137   \n",
       "unique           14      3                       109                   49   \n",
       "top     annotator_1     no  The Return of the Native  William Shakespeare   \n",
       "freq            760   1712                        20                  613   \n",
       "\n",
       "       character_1 character_2  affinity coarse_category fine_category detail  \\\n",
       "count         2137        2137      2137            2137          2137   2137   \n",
       "unique        1005         825         3               4            30    528   \n",
       "top      Joseph K.       Timon  positive          social        friend     NR   \n",
       "freq            15          17      1120             886           342   1591   \n",
       "\n",
       "                  book_name  \n",
       "count                  2137  \n",
       "unique                  109  \n",
       "top     Dracula_Bram_Stoker  \n",
       "freq                     20  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv('../data/character_relation_annotations.txt.gz', sep='\\t')\n",
    "# dropping values that have gibberish affinity - might transform this later based on category\n",
    "annotations = annotations[(annotations['affinity'] != 'NR') & (annotations['character_1'] != 'NR') & (annotations['character_2'] != 'NR')].copy()\n",
    "annotations['book_name'] = (annotations['title'] + ' ' + annotations['author']).str.replace(\"\\s\", \"_\")\n",
    "print(annotations.shape)\n",
    "# making sure no NR in character_1/character_2/affinity\n",
    "annotations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations[annotations['title'] == 'Oliver Twist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working around multiple annotators giving different marks - transforming into\n",
    "# real value based on mapping and averaging it\n",
    "def avg(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "affinity_mapping = {\n",
    "    'positive': 1,\n",
    "    'neutral': 0.5,\n",
    "    'negative': 0\n",
    "}\n",
    "annotations['num_affinity'] = annotations['affinity'].map(lambda aff: affinity_mapping[aff])\n",
    "all_df = pd.DataFrame(columns=['book_name', 'char_1', 'char_2', 'affinity'])\n",
    "by_book_annotations = col.defaultdict(col.defaultdict)\n",
    "def add_books_annotations(row):\n",
    "    book_name = row['book_name']\n",
    "    char_1, char_2 = sorted([row['character_1'], row['character_2']])\n",
    "    affinity = row['num_affinity']\n",
    "    by_book_annotations[book_name][char_1 + ':' + char_2] = (by_book_annotations[book_name][char_1 + ':' + char_2] if (char_1 + ':' + char_2) in by_book_annotations[book_name] else []) + [affinity]\n",
    "\n",
    "annotations.apply(add_books_annotations, axis=1)\n",
    "\n",
    "for book in by_book_annotations:\n",
    "    for pair in by_book_annotations[book]:\n",
    "        [char_1, char_2] = pair.split(':')\n",
    "        all_df = all_df.append([{\n",
    "            'book_name': book, 'char_1': char_1, 'char_2': char_2, 'affinity': avg(by_book_annotations[book][pair])\n",
    "        }])\n",
    "# voila, afinnity as single column dataframe with real values and all_x having book_name, char_1 and char_2 names\n",
    "all_y = all_df['affinity'].copy()\n",
    "all_X = all_df.drop('affinity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 109, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure all raw txt files are present for books\n",
    "titles = annotations['title'].unique()\n",
    "authors = [annotations[annotations['title'] == title]['author'][0:1].ravel()[0] for title in titles]\n",
    "existing_files = []\n",
    "names = []\n",
    "for pair in zip(titles, authors):\n",
    "    title, author = pair\n",
    "    name = re.sub(\"\\s\", \"_\", '{} {}'.format(title, author))\n",
    "    names.append(name)\n",
    "    file = '../data/books/{}.txt'.format(name)\n",
    "    existing_files.append(os.path.isfile(file))\n",
    "len(titles), len(existing_files), all(existing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [bu.Book(name, book_NLP_folder=\"../data/bookNLP_output\", source_folder=\"../data/books\") for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in books:\n",
    "    if len(book.tokens) < 100:\n",
    "        print(book.name, len(book.tokens), book.tokens.shape)\n",
    "# seems that most tokens are non-empty, yet issue with parsing the bookNLP token output into dataframes\n",
    "# underneath we are skipping those lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_label(val):\n",
    "    if val <= 0.33:\n",
    "        return 'negative'\n",
    "    if val <= 0.66:\n",
    "        return 'neutral'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictor = baseline.create_for(books, all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = baseline.predict(base_predictor, all_X)\n",
    "y_predicted.clip(0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(y_predicted, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(all_y.map(score_to_label), y_predicted.map(score_to_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more baseline, just to check - major class\n",
    "y_all_positive = np.ones_like(y_predicted)\n",
    "print(metrics.mean_squared_error(y_all_positive, all_y))\n",
    "print(metrics.classification_report(all_y.map(score_to_label), [score_to_label(val) for val in y_all_positive]))\n",
    "# well, at least our baseline does something more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books issues with chars\n",
    "# WARNING: Mrs. John Dashwood might have multiple aliases: ['Mrs. Dashwood', 'John Dashwood']\n",
    "# WARNING: Hector son of Priam might have multiple aliases: ['Hector', 'Priam']\n",
    "# WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
    "# WARNING: Mrs. Ned Hale might have multiple aliases: ['Mrs. Ned Hale', 'Ned Hale']\n",
    "# WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Elizabeth-Jane Newson', 'Newson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_chars = set([\"Mrs. John Dashwood\",\n",
    "\"Hector son of Priam\",\n",
    "\"Mrs. Joe Gargery\",\n",
    "\"Mrs. Joe Gargery\",\n",
    "\"Mrs. Ned Hale\",\n",
    "\"Elizabeth-Jane Newson\"])\n",
    "for (i,book) in enumerate(books):\n",
    "    for char in book.characters.meaningful:\n",
    "        if bu.longest_name(char) in bad_chars:\n",
    "            print(i, book.name, char['id'], bu.longest_name(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I identified these chars, I'm not sure what to do with all of this:\n",
    "\n",
    "1. Mrs. John Dashwood as identificator for wife of Mr. John Dashwood\n",
    "2. son of Priam mentioning Priam in no way refers to Priam himself\n",
    "3. Mrs. Joe Gargery as identificator for wife of Mr. Joe Gargery\n",
    "4. Not even sure about this one, but I think once again this is identificator for wife of Mr. Ned Hale\\\n",
    "5. Newson is used as reference to father of Elizabeth-Jane Newson\n",
    "\n",
    "so I'm considering adding following rules to bu.book_name_to_annotated_name()\n",
    "\n",
    "```\n",
    "Mrs. + Name != Name\n",
    "X son of Y != Y\n",
    "Firstname Lastname != Lastname\n",
    "```\n",
    "\n",
    "although first one could have another way of working out if we would have gender annotation for characters in dataset (given bookNLP infers gender), yet there are issues with bookNLP getting confused on its own with Mrs. John Dashwood (considering John Dashwood being same character and not Mr. John Dashwood who is character on his own)\n",
    "\n",
    "🤔 might be an issue for the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further work: affinity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Don_Quixote_Miguel_de_Cervantes Don Quixote ['Don Quixotes', 'Senor Don Quixote', 'lord Don Quixote']\n",
      "0 Don_Quixote_Miguel_de_Cervantes The Duke and Duchess ['Duke of Sesa', 'Duke Ricardo']\n",
      "0 Don_Quixote_Miguel_de_Cervantes Sancho Panza ['Sancho Panzas', 'Senor Don Sancho Panza']\n",
      "1 Little_Women_Louisa_May_Alcott Frederick Bhaer ['Mother Bhaer', 'Fred Vaughn']\n",
      "1 Little_Women_Louisa_May_Alcott Josephine March ['Miss Jo', 'Josephine']\n",
      "1 Little_Women_Louisa_May_Alcott Mr. Brooke ['Mrs. John Brooke', 'Mr. Brooke']\n",
      "1 Little_Women_Louisa_May_Alcott Sallie Gardiner ['Miss Sallie', 'Sallie Gardiner']\n",
      "2 Antony_and_Cleopatra_William_Shakespeare Octavius Caesar ['Octavius Caesar', 'Julius Caesar']\n",
      "2 Antony_and_Cleopatra_William_Shakespeare Antony ['MARK ANTONY', 'Antony Shall', 'An Antony']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "3 Sense_and_Sensibility_Jane_Austen John Dashwood ['Mrs. John Dashwood', 'Mr. John Dashwood']\n",
      "3 Sense_and_Sensibility_Jane_Austen Sir John Middleton ['John Middleton', 'Lady Middleton']\n",
      "4 Henry_VIII_William_Shakespeare Cardinal Wolsey ['Lord Cardinal', 'Wolsey']\n",
      "4 Henry_VIII_William_Shakespeare King Henry VIII ['Henry Guildford', 'Henry King']\n",
      "5 Richard_II_William_Shakespeare Henry Percy Earl of Northumberland; Lord Ross; and Lord Willoughby ['Lo', 'Willoughby', 'Harry Percy', 'Ross']\n",
      "5 Richard_II_William_Shakespeare John of Gaunt Duke of Lancaster ['John of Gaunt', 'Lancaster']\n",
      "5 Richard_II_William_Shakespeare The Duke of Aumerle ['Duke of Hereford', 'Lord Aumerle']\n",
      "6 Lord_Jim_Joseph_Conrad Jim ['Lord Jim', 'Tuan Jim', 'Jimmy']\n",
      "7 The_Count_of_Monte_Cristo_Alexandre_Dumas Baron Danglars ['Baron Danglars', 'M. Danglars']\n",
      "7 The_Count_of_Monte_Cristo_Alexandre_Dumas Monsieur Morrel ['M. Maximilian Morrel', 'Monsieur Baptistin', 'Monsieur Morrel', 'Monsieur de Morcerf']\n",
      "7 The_Count_of_Monte_Cristo_Alexandre_Dumas Caderousse ['M. Caderousse', 'Gaspard Caderousse']\n",
      "8 The_House_of_the_Seven_Gables_Nathaniel_Hawthorne Phoebe Pyncheon ['Miss Phoebe Pyncheon', 'Cousin Phoebe']\n",
      "8 The_House_of_the_Seven_Gables_Nathaniel_Hawthorne Old Jaffrey Pyncheon ['Cousin Jaffrey', 'Jaffrey Pyncheon']\n",
      "9 Typee_Herman_Melville Tommo ['Tom', 'Tommo']\n",
      "11 The_Three_Musketeers_Alexandre_Dumas Athos ['Messieurs Athos', 'Monsieur Athos']\n",
      "11 The_Three_Musketeers_Alexandre_Dumas Monsieur de Treville ['M. de Treville', 'Monsieur de Treville']\n",
      "11 The_Three_Musketeers_Alexandre_Dumas Madame de Coquenard ['Madame Coquenard', 'Monsieur Coquenard']\n",
      "12 Emma_Jane_Austen Mr. Robert Martin ['Mr. Robert Martin', '-- Robert Martin']\n",
      "12 Emma_Jane_Austen Frank Churchill ['-- Frank Churchill', 'Mr. Frank Churchill']\n",
      "12 Emma_Jane_Austen Isabella Knightley ['Mr. John Knightley', '-- Isabella']\n",
      "13 Persuasion_Jane_Austen Captain Frederick Wentworth ['Mr Wentworth', 'Frederick Wentworth']\n",
      "14 Oliver_Twist_Charles_Dickens Bill Sikes ['MR. WILLIAM SIKES', 'Bill Sikes']\n",
      "14 Oliver_Twist_Charles_Dickens Rose Maylie ['Rose Maylie', 'Miss Rose']\n",
      "15 The_Adventures_of_Tom_Sawyer_Mark_Twain Huckleberry Finn ['Huck Finn', 'Huckleberry Finn']\n",
      "17 Troilus_and_Cressida_William_Shakespeare Diomedes ['Diomedes', 'Diomed']\n",
      "17 Troilus_and_Cressida_William_Shakespeare Helen ['HELEN', 'Helenus']\n",
      "17 Troilus_and_Cressida_William_Shakespeare Cressida ['lady Cressid', 'Lady Cressida']\n",
      "18 Hard_Times_Charles_Dickens Josiah Bounderby ['MR. BOUNDERBY', 'Josiah Bounderby']\n",
      "20 Uncle_Tom&rsquo;s_Cabin_Harriet_Beecher_Stowe Eva ['Miss Eva', 'Evangeline']\n",
      "20 Uncle_Tom&rsquo;s_Cabin_Harriet_Beecher_Stowe Emily Shelby ['Mr. Shelby', 'Emily']\n",
      "21 Silas_Marner_George_Eliot Godfrey Cass ['Mrs. Godfrey Cass', 'Mr. Godfrey Cass']\n",
      "21 Silas_Marner_George_Eliot Dolly Winthrop ['Ben Winthrop', 'Dolly Winthrop']\n",
      "22 King_John_William_Shakespeare Philip ['KING PHILIP', '-- Philip']\n",
      "23 The_American_Henry_James Valentin de Bellegarde (the young Comte de Bellegarde) ['Valentin de Bellegarde', 'Mr. Valentin', 'M. de Bellegarde']\n",
      "23 The_American_Henry_James Tom Tristram ['Tom Tristram', 'Mrs. Tristram', 'Mr. Tristram']\n",
      "23 The_American_Henry_James Christopher Newman ['Christopher Newman', 'Mr. Newman']\n",
      "25 Swann's_Way_Marcel_Proust Verdurins ['M. Verdurin', 'Verdurins']\n",
      "25 Swann's_Way_Marcel_Proust Charles Swann ['Charles', 'M. Swann']\n",
      "25 Swann's_Way_Marcel_Proust Gilberte ['Gilbert', 'Gilberte Swann']\n",
      "26 Anna_Karenina_Leo_Tolstoy Sergei Alexeich Karenin (Seryozha) ['Alexey Alexandrovitch Karenin', 'Seryozha']\n",
      "26 Anna_Karenina_Leo_Tolstoy Stepan Arkadyich Oblonsky (Stiva) ['Stiva', 'Pyotr Oblonsky']\n",
      "26 Anna_Karenina_Leo_Tolstoy Ekaterina Alexandrovna Shcherbatskaya (Kitty) ['Kitty Shtcherbatskaya', 'Ekaterina']\n",
      "26 Anna_Karenina_Leo_Tolstoy Anna Arkadyevna Karenina ['Madame Karenina', 'Anna Arkadyevna']\n",
      "26 Anna_Karenina_Leo_Tolstoy Alexei Kirillovich Vronsky ['Kirillov', 'Alexey Vronsky']\n",
      "26 Anna_Karenina_Leo_Tolstoy Darya Alexandrovna Oblonskaya (Dolly) ['Oblonskaya', 'Dolly', 'Darya Alexandrovna']\n",
      "28 Henry_IV_Part_2_William_Shakespeare Mowbray and Hastings ['LORD MOWBRAY', 'LORD HASTINGS']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Edward ['Edwards', 'Sonne Edward', 'Edward King']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Warwick ['Warwicke', 'Warw', 'Lord Warwick']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Clifford ['Lord Clifford', 'Clif']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Prince Edward ['Prin', 'Ed', 'Prince Edward']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Richard ['Richard', 'Rich']\n",
      "30 Henry_VI_Part_3_William_Shakespeare Margaret ['Queene Margaret', 'Marg']\n",
      "31 Ulysses_James_Joyce Malachi (Buck) Mulligan ['Mr Malachi Mulligan', 'BUCK MULLIGAN']\n",
      "31 Ulysses_James_Joyce Josie (née Powell) and Denis Breen ['Denis Breen', 'Mrs Breen', 'Josie Powell']\n",
      "31 Ulysses_James_Joyce Cissy ['Ciss', 'CISSY CAFFREY']\n",
      "31 Ulysses_James_Joyce Leopold Bloom ['Leo', 'Mr Leopold Bloom']\n",
      "31 Ulysses_James_Joyce Marion (Molly) Bloom ['Mrs Marion Bloom', 'Molly', 'Mario']\n",
      "31 Ulysses_James_Joyce Haines ['MR HAINES', '-- Haines']\n",
      "31 Ulysses_James_Joyce Hugh (“Blazes”) Boylan ['Hugh C. Love', 'Blazes Boylan']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "32 The_Iliad_Homer Helen ['Helenus', 'Argive Helen']\n",
      "34 The_Merchant_of_Venice_William_Shakespeare Antonio ['Signior Antonio', 'O my Antonio']\n",
      "35 Adam_Bede_George_Eliot Captain Arthur Donnithorne ['Mr. Arthur Donnithorne', 'Squire Donnithorne']\n",
      "35 Adam_Bede_George_Eliot Rachel Poyser ['Rachel', 'Mrs. Poyser']\n",
      "36 Romeo_and_Juliet_William_Shakespeare Capulet ['Capulets', 'V. Capulet', 'Lady Capulet']\n",
      "36 Romeo_and_Juliet_William_Shakespeare Benvolio ['Ben', 'Benvolio']\n",
      "36 Romeo_and_Juliet_William_Shakespeare Montague ['Montague', 'Montagues']\n",
      "37 O_Pioneers!_Willa_Cather Marie Shabata ['Marie Shabata', 'Marie Tovesky']\n",
      "38 Narrative_of_the_Life_of_Frederick_Douglass_Frederick_Douglass William Lloyd Garrison ['Lloyd', 'Mr. William Hamilton']\n",
      "38 Narrative_of_the_Life_of_Frederick_Douglass_Frederick_Douglass Harriet Bailey ['Frederick Augustus Washington Bailey', 'Henry Bailey']\n",
      "39 Bleak_House_Charles_Dickens Sir Leicester Dedlock ['Leicester Dedlock', 'Sir Leicester']\n",
      "39 Bleak_House_Charles_Dickens Mr. John Jarndyce ['Mr. Jarndyce', 'Jo', 'John Jarndyce']\n",
      "39 Bleak_House_Charles_Dickens Mr. Matthew Bagnet ['Mr. Matthew Bagnet', 'Ma']\n",
      "40 Henry_VI_Part_2_William_Shakespeare Henry ['Henry King', 'Henry the Sixt']\n",
      "40 Henry_VI_Part_2_William_Shakespeare York ['Manet Yorke', 'York']\n",
      "40 Henry_VI_Part_2_William_Shakespeare Suffolk ['Suff', 'Lord Suffolke', 'Duke of Suffolke']\n",
      "41 Madame_Bovary_Gustave_Flaubert Rouault ['Monsieur Rouault', 'Mademoiselle Rouault']\n",
      "42 War_and_Peace_Leo_Tolstoy Helene Kuragina ['Countess Helene', 'Vasili Kuragin', 'Kuragina']\n",
      "42 War_and_Peace_Leo_Tolstoy Prince Bolkonski ['Prince Andrew', 'Prince Anatole', 'Prince Bolkonski', 'Prince Vasili']\n",
      "42 War_and_Peace_Leo_Tolstoy Julie Karagina ['Julie Karagina', 'Julie Drubetskaya']\n",
      "42 War_and_Peace_Leo_Tolstoy Countess Natalya Rostova ['Nataly', 'Count Bennigsen']\n",
      "42 War_and_Peace_Leo_Tolstoy Nicholas Rostov ['Nicholas Rostov', 'Prince Nicholas']\n",
      "43 Middlemarch_George_Eliot Tertius Lydgate ['Mr. Lydgate', 'Tertius']\n",
      "43 Middlemarch_George_Eliot Will Ladislaw ['Mr. Ladislaw', 'Will Ladislaw']\n",
      "43 Middlemarch_George_Eliot Edward Casaubon ['MR. CASAUBON', 'EDWARD CASAUBON']\n",
      "43 Middlemarch_George_Eliot Fred Vincy ['Mr. Fred', 'Fred Vincy']\n",
      "43 Middlemarch_George_Eliot Arthur Brooke ['Arthur', 'MISS BROOKE']\n",
      "43 Middlemarch_George_Eliot Nicholas Bulstrode ['Nicholas Bulstrode', 'Mr. Bulstrode']\n",
      "44 Pride_and_Prejudice_Jane_Austen Georgiana Darcy ['Mr. Darcy', 'Georgiana']\n",
      "44 Pride_and_Prejudice_Jane_Austen George Wickham ['George Wickham', 'Mr. Wickham']\n",
      "44 Pride_and_Prejudice_Jane_Austen Elizabeth Bennet ['Miss Eliza Bennet', 'Miss Elizabeth Bennet']\n",
      "44 Pride_and_Prejudice_Jane_Austen Charlotte Lucas ['Lady Lucas', 'Charlotte Lucas']\n",
      "44 Pride_and_Prejudice_Jane_Austen Mr. and Mrs. Gardiner ['Mrs. Gardiner', 'Mr. Gardiner']\n",
      "44 Pride_and_Prejudice_Jane_Austen Miss Bingley ['Miss Bingley', 'Mr. Bingley']\n",
      "46 The_Jungle_Upton_Sinclair Antanas Rudkus ['Antanas Rudkus', 'Dede Antanas']\n",
      "47 Henry_VI_Part_1_William_Shakespeare King Henry VI ['Henry the Fifth', 'King']\n",
      "47 Henry_VI_Part_1_William_Shakespeare Talbot ['LORD TALBOT', 'JOHN TALBOT']\n",
      "48 Anne_of_Green_Gables_L._M._Montgomery Gilbert Blythe ['Gilbert Blythe', 'Gil']\n",
      "49 A_Midsummer_Night&rsquo;s_Dream_William_Shakespeare Helena ['Helena', 'Helen']\n",
      "51 William_Shakespeare_Henry_IV_Part_1 Prince Harry ['Harry Percy', 'Prince of Wales']\n",
      "51 William_Shakespeare_Henry_IV_Part_1 Sir John Falstaff ['Jack Falstaff', 'John Falstaff']\n",
      "51 William_Shakespeare_Henry_IV_Part_1 King Henry IV ['King', 'Henry IV']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "53 Spanish_Tragedy_Thomas_Kyd Isabella ['Isabella', 'ISABELL']\n",
      "53 Spanish_Tragedy_Thomas_Kyd Horatio ['Signior Horatio', 'DON HORATIO']\n",
      "53 Spanish_Tragedy_Thomas_Kyd Balthazar ['Don Balthazar', 'Prince Balthazar']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "55 Great_Expectations_Charles_Dickens Uncle Pumblechook ['Mr. Pumblechook', 'Uncle Pumblechook']\n",
      "55 Great_Expectations_Charles_Dickens Wemmick ['Mrs. Wemmick', 'Mr. Wemmick']\n",
      "55 Great_Expectations_Charles_Dickens Jaggers ['MR. JAGGERS', 'Mr Jaggers']\n",
      "55 Great_Expectations_Charles_Dickens Bentley Drummle ['Mrs. Bentley Drummle', 'Mr. Drummle']\n",
      "56 Henry_V_William_Shakespeare and Grey Three conspirators against King Henry. ['Henry Lord Scroop', 'King']\n",
      "56 Henry_V_William_Shakespeare The King of France Charles VI. ['Charles Delabreth', 'Charles the Great']\n",
      "58 As_You_Like_It_William_Shakespeare Rosalind ['Rosalinde', 'Rosalind']\n",
      "59 Dr._Jekyll_and_Mr._Hyde_Robert_Louis_Stevenson Mr. Edward Hyde ['Mr. Hyde', 'Edward Hyde']\n",
      "60 Dracula_Bram_Stoker Arthur Holmwood ['Arthur Holmwood', 'Art']\n",
      "60 Dracula_Bram_Stoker Van Helsing ['Dr. Van Helsing', 'ABRAHAM VAN HELSING']\n",
      "61 The_House_of_Mirth_Edith_Wharton Jack Stepney and Gwen Stepney ['Gwen Van Osburgh', 'Mrs. Jack Stepney', 'Gwen Stepney']\n",
      "61 The_House_of_Mirth_Edith_Wharton Judy Trenor ['Mrs. Trenor', 'Judy Trenor']\n",
      "61 The_House_of_Mirth_Edith_Wharton Carry Fisher ['Carry Fisher', 'Mrs. Fisher']\n",
      "63 Howards_End_E._M._Forster Paul Wilcox ['Mr. Wilcox', 'St. Paul', 'Paul Wilcox', 'Mrs. Warrington Wilcox']\n",
      "63 Howards_End_E._M._Forster Margaret Schlegel ['MISS SCHLEGEL', 'Margaret']\n",
      "64 A_Doll&rsquo;s_House_Henrik_Ibsen Krogstad ['Nils Krogstad', 'Mr. Krogstad']\n",
      "66 Hedda_Gabler_Henrik_Ibsen Jürgen Tesman ['MISS JULIANA TESMAN', 'Dr. Tesman']\n",
      "68 Ghosts_Henrik_Ibsen Regina Engstrand ['REGINA', 'Jacob Engstrand']\n",
      "68 Ghosts_Henrik_Ibsen Oswald Alving ['MRS. ALVING', 'MRS ALVING', 'OSWALD ALVING']\n",
      "69 Far_from_the_Madding_Crowd_Thomas_Hardy Cainy Ball ['Cainy Ball', 'Cain Ball']\n",
      "69 Far_from_the_Madding_Crowd_Thomas_Hardy William Boldwood ['William Smallbury', 'Mr. Boldwood']\n",
      "69 Far_from_the_Madding_Crowd_Thomas_Hardy Sergeant Francis (Frank) Troy ['Frank', 'FRANCIS TROY']\n",
      "69 Far_from_the_Madding_Crowd_Thomas_Hardy Joseph Poorgrass ['Joseph Poor', 'Joseph Poorgrass']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "70 Ethan_Frome_Edith_Wharton Mattie Silver ['Mattie Silver', 'Matt']\n",
      "72 King_Lear_William_Shakespeare Regan ['O Regan', 'Reg']\n",
      "73 Sister_Carrie_Theodore_Dreiser Mrs. Vance ['Mr. Vance', 'Mrs. Vance']\n",
      "73 Sister_Carrie_Theodore_Dreiser Fitzgerald and Moy ['Fitzgerald', 'Moy']\n",
      "73 Sister_Carrie_Theodore_Dreiser Hanson ['Hansons', 'Hanson']\n",
      "73 Sister_Carrie_Theodore_Dreiser Charlie Drouet ['Mrs. Drouet', 'Charlie']\n",
      "73 Sister_Carrie_Theodore_Dreiser Julia Hurstwood ['Mrs. Julia Hurstwood', 'Mr. Hurstwood']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Northanger_Abbey_Jane_Austen Henry Tilney ['Mr. Henry Tilney', 'Miss Tilney']\n",
      "75 Julius_Caesar_William_Shakespeare Cassius ['Caie Cassi', 'Cass']\n",
      "75 Julius_Caesar_William_Shakespeare Decius ['Deci', 'Decius Brutus']\n",
      "75 Julius_Caesar_William_Shakespeare Octavius ['Octavi', 'OCTAVIUS']\n",
      "77 The_Taming_of_the_Shrew_William_Shakespeare Baptista ['Signior Baptista', 'BAPTISTA MINOLA']\n",
      "77 The_Taming_of_the_Shrew_William_Shakespeare Gremio and Hortensio ['Signior Hortensio', 'Signior Gremio']\n",
      "80 Mansfield_Park_Jane_Austen Mary Crawford ['Miss Crawford', 'Mary Crawford', 'Mrs. Crawford']\n",
      "80 Mansfield_Park_Jane_Austen Maria Bertram ['Maria Bertram', 'Miss Maria']\n",
      "82 Major_Barbara_George_Bernard_Shaw Lady Britomart Undershaft ['Lady Brit', 'Lady Britomart']\n",
      "84 Main_Street_Sinclair_Lewis Vida Sherwin ['Vida Sherwins', 'Miss Vida Sherwin']\n",
      "84 Main_Street_Sinclair_Lewis Raymond Wutherspoon ['Ray', 'Raymie Wutherspoon', 'Raymond Wutherspoon']\n",
      "84 Main_Street_Sinclair_Lewis Maud Dyer ['Mrs. Dave Dyer', 'Maud Dyer', 'Ma Dawson']\n",
      "84 Main_Street_Sinclair_Lewis Aunt Bessie and Uncle Whittier Smail ['Uncle Whittier', 'Aunt Bessie', 'Uncle Whit']\n",
      "84 Main_Street_Sinclair_Lewis Kennicott ['Kennicotts', 'Dr. Will Kennicott', 'Carol Kennicott', 'Doc Kennicott', 'Mrs. Will Kennicott']\n",
      "86 Jude_the_Obscure_Thomas_Hardy Richard Phillotson ['Mr. Phillotson', 'Mrs. Richard Phillotson']\n",
      "87 Kidnapped_Robert_Louis_Stevenson Mr. Campbell ['COLIN CAMPBELL', 'Mr. Campbell']\n",
      "87 Kidnapped_Robert_Louis_Stevenson James of the Glens ['JAMES STEWART', 'James of the Glens']\n",
      "88 Measure_for_Measure_William_Shakespeare Isabella ['Isabella', 'Isabel']\n",
      "89 Titus_Andronicus_William_Shakespeare Chiron and Demetrius ['Demetrius', 'Chiron']\n",
      "92 The_Trial_Franz_Kafka Joseph K. ['Mr. K.', 'Josef K.']\n",
      "95 A_Tale_of_Two_Cities_Charles_Dickens Sydney Carton ['Sydney Carton', 'Mr. Carton']\n",
      "95 A_Tale_of_Two_Cities_Charles_Dickens Monsieur Defarge ['Monsieur the Marquis', 'Monsieur Defarge']\n",
      "95 A_Tale_of_Two_Cities_Charles_Dickens Lucie Manette ['Miss Manette', 'Lucie Manette', 'Miss Lucie']\n",
      "96 The_Tempest_William_Shakespeare Trinculo & Stephano ['Trinculo', 'Stephano']\n",
      "97 The_Scarlet_Letter_Nathaniel_Hawthorne Reverend Mr. John Wilson ['John Wilson', 'Mr. Wilson']\n",
      "97 The_Scarlet_Letter_Nathaniel_Hawthorne Reverend Arthur Dimmesdale ['Arthur Dimmesdale', 'Mr. Dimmesdale']\n",
      "98 Maggie:_A_Girl_of_the_Streets_Stephen_Crane Nellie ['Nell', 'Nellie']\n",
      "98 Maggie:_A_Girl_of_the_Streets_Stephen_Crane Jimmie ['Jimmie', 'Jim']\n",
      "99 The_Two_Gentlemen_of_Verona_William_Shakespeare Silvia ['Madam Silvia', 'lady Silvia']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "102 The_Mayor_of_Casterbridge_Thomas_Hardy Newson ['Mrs. Henchard-Newson', 'Richard Newson', 'Mrs. Newson', 'Miss Newson', 'Elizabeth-Jane Newson']\n",
      "102 The_Mayor_of_Casterbridge_Thomas_Hardy Joshua Jopp ['Jopp', 'Joshua']\n",
      "102 The_Mayor_of_Casterbridge_Thomas_Hardy Lucetta Templeman ['LUCETTA', 'Miss Templeman']\n",
      "103 Love's_Labours_Lost_William_Shakespeare Berowne ['Monsieur Berowne', 'Lord Berowne']\n",
      "104 Much_Ado_About_Nothing_William_Shakespeare Claudio ['Claud', 'Claudio']\n",
      "104 Much_Ado_About_Nothing_William_Shakespeare Benedick ['Bene', 'Signior Benedick']\n",
      "104 Much_Ado_About_Nothing_William_Shakespeare Leonato ['Leon', 'Signior Leonato']\n",
      "106 Treasure_Island_Robert_Louis_Stevenson Squire Trelawney ['Squire', 'Mr. Trelawney']\n",
      "106 Treasure_Island_Robert_Louis_Stevenson Billy Bones ['Bill', 'Billy Bones']\n",
      "107 Siddhartha_Hermann_Hesse Siddhartha ['Samana Siddhartha', 'Siddhartha bei den Samanas', 'Siddharthas Seele']\n",
      "108 The_Return_of_the_Native_Thomas_Hardy Diggory Venn ['Mrs. Venn', 'Diggory Venn']\n",
      "108 The_Return_of_the_Native_Thomas_Hardy Damon Wildeve ['MR. WILDEVE', 'Damon']\n",
      "108 The_Return_of_the_Native_Thomas_Hardy Eustacia Vye ['Miss Eustacia', 'Eustacia Vye']\n"
     ]
    }
   ],
   "source": [
    "# one thing that was suspicious - for first book there were multiple characters that were mapping to same name\n",
    "# in annotations, so let's see how many of those are there\n",
    "\n",
    "for i, book in enumerate(books):\n",
    "    chars = col.defaultdict(list)\n",
    "    book_name = book.name\n",
    "    subset = all_X[all_X['book_name'] == book_name]\n",
    "    present_chars = pd.concat([subset['char_1'], subset['char_2']]).unique()\n",
    "    for char in book.characters.meaningful:\n",
    "        name = bu.book_name_to_annotated_name(book_name, char, present_chars, False)\n",
    "        if name:\n",
    "            chars[name].append(char)\n",
    "    #         print(name, \"|\", bu.longest_name(char))\n",
    "    for key in chars:\n",
    "        if len(chars[key]) > 1:\n",
    "            print(i, book_name, key, [bu.longest_name(char) for char in chars[key]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, seems that we need to 'merge' chars. First, I would try doing that according to some rules:\n",
    "- Name == Senor Name == lord Name\n",
    "- Name === Senor Don Name\n",
    "- Miss Firstname ~~ Miss Firstname Lastname (but not Mrs)\n",
    "- Mrs. Firstname Lastname ~~ Mrs. Lastname\n",
    "- some name alternatives might be used Richard -> Dick, William -> Bob, etc\n",
    "- some initials can be used instead of firstname\n",
    "- might want to clean `--` in some names and merge with some prefix\n",
    "- nicknames used in parenthesis might exactly match with name or might be used instead of first name\n",
    "\n",
    "Basically, might try to rely on gender annotated to char and ability to deduct gender of name based on prefixes used in name + some processing for nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>affinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don_Quixote_Miguel_de_Cervantes</td>\n",
       "      <td>Don Quixote</td>\n",
       "      <td>The Duke and Duchess</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don_Quixote_Miguel_de_Cervantes</td>\n",
       "      <td>Sancho Panza</td>\n",
       "      <td>The Duke and Duchess</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don_Quixote_Miguel_de_Cervantes</td>\n",
       "      <td>Altisidora</td>\n",
       "      <td>The Duke and Duchess</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard_II_William_Shakespeare</td>\n",
       "      <td>Henry Bolingbroke Duke of Herford</td>\n",
       "      <td>Henry Percy Earl of Northumberland; Lord Ross;...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry_IV_Part_2_William_Shakespeare</td>\n",
       "      <td>Duke of Gloucester; and Thomas</td>\n",
       "      <td>King Henry IV</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry_IV_Part_2_William_Shakespeare</td>\n",
       "      <td>Mowbray and Hastings</td>\n",
       "      <td>Prince Hal (later King Henry V)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulysses_James_Joyce</td>\n",
       "      <td>Josie (née Powell) and Denis Breen</td>\n",
       "      <td>Leopold Bloom</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pride_and_Prejudice_Jane_Austen</td>\n",
       "      <td>Elizabeth Bennet</td>\n",
       "      <td>Mr. and Mrs. Gardiner</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_House_of_Mirth_Edith_Wharton</td>\n",
       "      <td>Jack Stepney and Gwen Stepney</td>\n",
       "      <td>Lily Bart</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamlet_William_Shakespeare</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>Rosencrantz and Guildenstern</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamlet_William_Shakespeare</td>\n",
       "      <td>Claudius</td>\n",
       "      <td>Voltimand and Cornelius</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sister_Carrie_Theodore_Dreiser</td>\n",
       "      <td>Fitzgerald and Moy</td>\n",
       "      <td>George Hurstwood</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northanger_Abbey_Jane_Austen</td>\n",
       "      <td>Catherine Morland</td>\n",
       "      <td>Mr. and Mrs. Allen</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Taming_of_the_Shrew_William_Shakespeare</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Gremio and Hortensio</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Taming_of_the_Shrew_William_Shakespeare</td>\n",
       "      <td>Gremio and Hortensio</td>\n",
       "      <td>Lucentio</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Taming_of_the_Shrew_William_Shakespeare</td>\n",
       "      <td>Gremio and Hortensio</td>\n",
       "      <td>Petruchio</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main_Street_Sinclair_Lewis</td>\n",
       "      <td>Aunt Bessie and Uncle Whittier Smail</td>\n",
       "      <td>Kennicott</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titus_Andronicus_William_Shakespeare</td>\n",
       "      <td>Chiron and Demetrius</td>\n",
       "      <td>Tamora</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     book_name  \\\n",
       "0              Don_Quixote_Miguel_de_Cervantes   \n",
       "0              Don_Quixote_Miguel_de_Cervantes   \n",
       "0              Don_Quixote_Miguel_de_Cervantes   \n",
       "0               Richard_II_William_Shakespeare   \n",
       "0          Henry_IV_Part_2_William_Shakespeare   \n",
       "0          Henry_IV_Part_2_William_Shakespeare   \n",
       "0                          Ulysses_James_Joyce   \n",
       "0              Pride_and_Prejudice_Jane_Austen   \n",
       "0             The_House_of_Mirth_Edith_Wharton   \n",
       "0                   Hamlet_William_Shakespeare   \n",
       "0                   Hamlet_William_Shakespeare   \n",
       "0               Sister_Carrie_Theodore_Dreiser   \n",
       "0                 Northanger_Abbey_Jane_Austen   \n",
       "0  The_Taming_of_the_Shrew_William_Shakespeare   \n",
       "0  The_Taming_of_the_Shrew_William_Shakespeare   \n",
       "0  The_Taming_of_the_Shrew_William_Shakespeare   \n",
       "0                   Main_Street_Sinclair_Lewis   \n",
       "0         Titus_Andronicus_William_Shakespeare   \n",
       "\n",
       "                                 char_1  \\\n",
       "0                           Don Quixote   \n",
       "0                          Sancho Panza   \n",
       "0                            Altisidora   \n",
       "0     Henry Bolingbroke Duke of Herford   \n",
       "0        Duke of Gloucester; and Thomas   \n",
       "0                  Mowbray and Hastings   \n",
       "0    Josie (née Powell) and Denis Breen   \n",
       "0                      Elizabeth Bennet   \n",
       "0         Jack Stepney and Gwen Stepney   \n",
       "0                                Hamlet   \n",
       "0                              Claudius   \n",
       "0                    Fitzgerald and Moy   \n",
       "0                     Catherine Morland   \n",
       "0                                Bianca   \n",
       "0                  Gremio and Hortensio   \n",
       "0                  Gremio and Hortensio   \n",
       "0  Aunt Bessie and Uncle Whittier Smail   \n",
       "0                  Chiron and Demetrius   \n",
       "\n",
       "                                              char_2  affinity  \n",
       "0                               The Duke and Duchess      0.25  \n",
       "0                               The Duke and Duchess      0.25  \n",
       "0                               The Duke and Duchess      0.75  \n",
       "0  Henry Percy Earl of Northumberland; Lord Ross;...      1.00  \n",
       "0                                      King Henry IV      1.00  \n",
       "0                    Prince Hal (later King Henry V)      0.00  \n",
       "0                                      Leopold Bloom      0.50  \n",
       "0                              Mr. and Mrs. Gardiner      1.00  \n",
       "0                                          Lily Bart      1.00  \n",
       "0                       Rosencrantz and Guildenstern      0.00  \n",
       "0                            Voltimand and Cornelius      1.00  \n",
       "0                                   George Hurstwood      0.50  \n",
       "0                                 Mr. and Mrs. Allen      1.00  \n",
       "0                               Gremio and Hortensio      0.00  \n",
       "0                                           Lucentio      0.00  \n",
       "0                                          Petruchio      1.00  \n",
       "0                                          Kennicott      0.50  \n",
       "0                                             Tamora      0.50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yet another issue with annotated data - there are entries X and Y\n",
    "all_df[(all_df['char_1'].str.contains(' and ')) | (all_df['char_2'].str.contains(' and '))]\n",
    "# further work - need to split it into multiple entries, issue here is what to do with annotation to 'pair' + there\n",
    "# won't be relations between chars in pair 🤔 - assuming X to Y & Z has same relation as X to Y and X to Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://git.io/vpzth\n",
    "def splitDataFrameList(df,target_column,separator):\n",
    "    ''' df = dataframe to split,\n",
    "    target_column = the column containing the values to split\n",
    "    separator = the symbol used to perform the split\n",
    "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "    The values in the other columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "    row_accumulator = []\n",
    "\n",
    "    def splitListToRows(row, separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "\n",
    "    df.apply(splitListToRows, axis=1, args = (separator, ))\n",
    "    new_df = pd.DataFrame(row_accumulator)\n",
    "    return new_df\n",
    "\n",
    "new_df = splitDataFrameList(all_df, 'char_1', ' and ')\n",
    "new_df = splitDataFrameList(new_df, 'char_2', ' and ')\n",
    "\n",
    "all_y = new_df['affinity'].copy()\n",
    "all_X = new_df.drop('affinity', axis=1)\n",
    "# Removed cells retraining baseline as we got 36 extra rows in X / Y and it didn't affect any metrics,\n",
    "# apart from droping by 0.01 recall for one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First point: find 'main' characters close to those in annotations\n",
    "# might putting this into book_utils.py\n",
    "def get_rel_stats(book):\n",
    "    meaningful_rels = {}\n",
    "    rels = col.defaultdict(col.Counter)\n",
    "    for p in book.paragraphs:\n",
    "        chars = set(p[p['characterId'] > 0 ]['characterId'].unique())\n",
    "        for char in chars:\n",
    "            if len(chars) > 1:\n",
    "                other_chars = chars - set([char])\n",
    "                rels[char].update(list(other_chars))\n",
    "    sums = {}\n",
    "    counts = {}\n",
    "    for char in rels:\n",
    "        sums[char] = sum(rels[char].values())\n",
    "        counts[char] = len(rels[char].values())\n",
    "    return rels, sums, counts\n",
    "def get_meaningful_chars(book):\n",
    "    rels, sums, counts = get_rel_stats(book)\n",
    "    possible_chars = book.characters.meaningful\n",
    "    \n",
    "    filtered = [char for char in possible_chars if char['id'] in sums and sums[char['id']] > 3]\n",
    "    return filtered\n",
    "\n",
    "def evaluate(book, chars, present_chars):\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    found_chars = set([])\n",
    "    for char in chars:\n",
    "        name = bu.book_name_to_annotated_name(book.name, char, present_chars, False)\n",
    "        if name:\n",
    "            found_chars.update([name])\n",
    "#     print(found_chars)\n",
    "#     print(set(present_chars) - found_chars)        \n",
    "    return len(found_chars) == len(present_chars), len(present_chars) - len(found_chars), len(chars) - len(present_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/109 [00:12<12:04,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Little_Women_Louisa_May_Alcott\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 4/109 [00:15<07:20,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 10/109 [00:39<06:52,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Typee_Herman_Melville\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 13/109 [00:54<08:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Emma_Jane_Austen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 16/109 [01:04<05:52,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for The_Adventures_of_Tom_Sawyer_Mark_Twain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 32/109 [01:56<06:26,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Ulysses_James_Joyce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 33/109 [01:58<05:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 38/109 [02:04<02:33,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for O_Pioneers!_Willa_Cather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 43/109 [03:00<14:21, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for War_and_Peace_Leo_Tolstoy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 44/109 [03:12<13:59, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Middlemarch_George_Eliot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 45/109 [03:16<10:46, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Pride_and_Prejudice_Jane_Austen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 49/109 [03:22<03:45,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Anne_of_Green_Gables_L._M._Montgomery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 51/109 [03:27<03:08,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Babbitt_Sinclair_Lewis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 53/109 [03:32<02:41,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 56/109 [03:41<03:03,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 61/109 [03:50<01:50,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Dracula_Bram_Stoker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 62/109 [03:53<01:54,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for The_House_of_Mirth_Edith_Wharton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 64/109 [03:59<02:17,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Howards_End_E._M._Forster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 70/109 [04:09<00:56,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Far_from_the_Madding_Crowd_Thomas_Hardy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 71/109 [04:10<00:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 78/109 [04:29<01:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for The_Taming_of_the_Shrew_William_Shakespeare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 81/109 [04:35<01:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Mansfield_Park_Jane_Austen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 84/109 [04:45<01:22,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for The_Portrait_of_a_Lady_Henry_James\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 85/109 [04:51<01:41,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Main_Street_Sinclair_Lewis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 102/109 [05:21<00:10,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all for Pygmalion_George_Bernard_Shaw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 103/109 [05:25<00:13,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "got_all for The_Mayor_of_Casterbridge_Thomas_Hardy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [05:39<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got_all 21, total_unmatched 357, total_extra 4211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "got_all_count = 0\n",
    "total_unmatched = 0\n",
    "total_extra = 0\n",
    "for book in tqdm(books):\n",
    "    # rels, sums, counts = get_rel_stats(book)\n",
    "    meaningful = get_meaningful_chars(book)\n",
    "    target_X = all_X[all_X['book_name'] == book.name]\n",
    "    present_chars = pd.concat([target_X['char_1'], target_X['char_2']]).unique()\n",
    "    got_all, unmatched, extra_matched = evaluate(book, meaningful, present_chars)\n",
    "    if got_all:\n",
    "        got_all_count += 1\n",
    "        print(f'got_all for {book.name}')\n",
    "    total_unmatched += unmatched\n",
    "    total_extra += extra_matched\n",
    "print(f'got_all {got_all_count}, total_unmatched {total_unmatched}, total_extra {total_extra}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sum threshold 10 - got_all 8, total_unmatched 533, total_extra 1145\n",
    "# with sum threshold 5 - got_all 12, total_unmatched 430, total_extra 2220\n",
    "# 🌟 with sum threshold 3 - got_all 16, total_unmatched 394, total_extra 2940\n",
    "# with sum threshold 1 - got_all 19, total_unmatched 353, total_extra 3950\n",
    "# with sum threshold 0 - got_all 19, total_unmatched 339, total_extra 4501\n",
    "# with counts threshold 2 - got_all 15, total_unmatched 399, total_extra 3172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, after putting some time into trying to identify subset of characters that are important to make this slightly faster to compute and more interesting in terms of end-2-end running and not just classification by making sure we are capturing all the important characters and as little as possible unimportant ones I have 2 things to share:\n",
    "- some simple metric isn't good enough and this might need another model 🤦 \n",
    "- no need to care about 'extra' characters, but should aim at do finding all the chars that were labelled\n",
    "(partially this is caused by 'unmerged'chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1486,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = annotations[['book_name', 'character_1', 'character_2', 'coarse_category']].copy()\n",
    "new_categories = splitDataFrameList(categories, 'character_1', ' and ')\n",
    "new_categories = splitDataFrameList(new_categories, 'character_2', ' and ')\n",
    "\n",
    "def lookup_category(row):\n",
    "    matching_categories = new_categories[\n",
    "        (new_categories['book_name'] == row['book_name']) &\n",
    "        ((new_categories['character_1'] == row['char_1']) & (new_categories['character_2'] == row['char_2']) |\n",
    "        (new_categories['character_2'] == row['char_1']) & (new_categories['character_1'] == row['char_2']))\n",
    "        & (new_categories['coarse_category'] != 'NR')\n",
    "    ]['coarse_category'].unique()\n",
    "    # Okay, super weird thing, but going with the whim here and might redo later\n",
    "    # professional > familial > social\n",
    "    if 'professional' in matching_categories:\n",
    "        return 'professional'\n",
    "    if 'familial' in matching_categories:\n",
    "        return 'familial'\n",
    "    if 'social' in matching_categories:\n",
    "        return 'social'\n",
    "\n",
    "new_df['category'] = new_df.apply(lookup_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "social          886\n",
       "familial        823\n",
       "professional    421\n",
       "NR                7\n",
       "Name: coarse_category, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories['coarse_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "social          897\n",
       "familial        830\n",
       "professional    427\n",
       "NR                7\n",
       "Name: coarse_category, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_categories['coarse_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "social          589\n",
       "familial        559\n",
       "professional    335\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given we had overlaps, there would be fewer entries\n",
    "new_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = new_df[['affinity', 'category']].copy()\n",
    "all_X = new_df.drop(['affinity', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_mapping = {}\n",
    "book_names = all_X['book_name'].unique()\n",
    "for name in book_names:\n",
    "    found = False\n",
    "    for book in books:\n",
    "        if found:\n",
    "            break\n",
    "        if book.name == name:\n",
    "            book_mapping[name] = book\n",
    "            found = True\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       1483\n",
       "unique         3\n",
       "top       social\n",
       "freq         589\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y['category'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aff, X_test_aff, y_train_aff, y_test_aff = train_test_split(all_X, all_y['affinity'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 48/1486 [00:31<06:55,  3.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 52/1486 [00:37<14:21,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 55/1486 [00:37<11:12,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n",
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 63/1486 [00:37<08:07,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. John Dashwood might have multiple aliases: ['John Dashwood', 'Mrs. Dashwood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 454/1486 [04:24<04:43,  3.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 462/1486 [04:26<05:53,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 468/1486 [04:26<04:13,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n",
      "WARNING: Hector son of Priam might have multiple aliases: ['Priam', 'Hector']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 745/1486 [06:57<04:05,  3.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 748/1486 [07:00<06:27,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n",
      "WARNING: Le Bret et Ragueneau might have multiple aliases: ['Le Bret', 'Ragueneau']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 775/1486 [07:05<03:51,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 787/1486 [07:16<04:37,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 796/1486 [07:16<02:26,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n",
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 800/1486 [07:16<01:49,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Joe Gargery might have multiple aliases: ['Joe Gargery', 'Mrs. Joe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 983/1486 [08:18<04:09,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 992/1486 [08:19<05:10,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n",
      "WARNING: Mrs. Ned Hale might have multiple aliases: ['Ned Hale', 'Mrs. Ned Hale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1390/1486 [10:39<00:23,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 1392/1486 [10:46<01:47,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 1394/1486 [10:46<01:18,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 1397/1486 [10:46<00:53,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1406/1486 [10:47<00:25,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n",
      "WARNING: Elizabeth-Jane Newson might have multiple aliases: ['Newson', 'Elizabeth-Jane Newson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1486/1486 [11:11<00:00,  2.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This was supposed to be a separate incapsulated fn, but I forgot about it 😅\n",
    "X = all_X # selecting subset \n",
    "xs = X.to_dict(orient='records')\n",
    "\n",
    "all_paragraphs = []\n",
    "paragraphs_mapping = col.defaultdict(str)\n",
    "present_chars_mapping = {}\n",
    "books_to_paragraphs_ids = col.defaultdict(dict)\n",
    "\n",
    "for x in tqdm(xs):\n",
    "\n",
    "    book_name = x['book_name']\n",
    "    char_1 = x['char_1']\n",
    "    char_2 = x['char_2']\n",
    "\n",
    "    book = book_mapping[book_name]\n",
    "    if not book in present_chars_mapping:\n",
    "        present_chars = get_meaningful_chars(book)\n",
    "        present_chars_mapping[book] = present_chars\n",
    "    else:\n",
    "        present_chars = present_chars_mapping[book]\n",
    "\n",
    "    proper_subset = X[X['book_name'] == book_name]\n",
    "    annotated_chars = pd.concat([proper_subset['char_1'], proper_subset['char_2']]).unique()\n",
    "\n",
    "    char_1_obj = None\n",
    "    char_2_obj = None\n",
    "    for char in present_chars:\n",
    "        annotated_name = bu.book_name_to_annotated_name(book.name, char, annotated_chars, False) \n",
    "        if annotated_name and annotated_name == char_1:\n",
    "            char_1_obj = char\n",
    "        elif annotated_name and annotated_name == char_2:\n",
    "            char_2_obj = char\n",
    "    if not char_1_obj and not char_2_obj:\n",
    "#         print(f\"Warning: could not find {char_1} & {char_2} for {book_name}\")\n",
    "        continue\n",
    "    elif not char_1_obj:\n",
    "#         print(f\"Warning: could not find {char_1} for {book_name}\")\n",
    "        continue\n",
    "    elif not char_2_obj:\n",
    "#         print(f\"Warning: could not find {char_2} for {book_name}\")\n",
    "        continue\n",
    "    if not book in books_to_paragraphs_ids:\n",
    "        for p in book.paragraphs:\n",
    "            chars = frozenset(p[p['characterId'] > 0 ]['characterId'].unique())\n",
    "            if chars not in books_to_paragraphs_ids[book]:\n",
    "                books_to_paragraphs_ids[book][chars] = list()\n",
    "            id = p['paragraphId'].unique()[0]\n",
    "            books_to_paragraphs_ids[book][chars].append(id)\n",
    "    for charset in books_to_paragraphs_ids[book]:\n",
    "        if char_1_obj['id'] in charset and char_2_obj['id'] in charset:\n",
    "            paragraphIds = books_to_paragraphs_ids[book][charset]\n",
    "            p_tokens = book.tokens[(book.tokens['paragraphId'].isin(paragraphIds)) & (book.tokens['characterId'] == -1)]\n",
    "            # sentence = ' '.join([str(i) for i in p_tokens['originalWord'].ravel()])\n",
    "            all_words = ' '.join([stemmer.stem(str(i)) for i in p_tokens['normalizedWord'].ravel()])\n",
    "            all_paragraphs.append(all_words)\n",
    "            paragraphs_mapping[f\"{book_name}_{char_1}_{char_2}\"] += all_words\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoyalCountVectorizer(CountVectorizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LoyalCountVectorizer, self).__init__(*args, **kwargs)\n",
    "        self._was_it_fitted = False\n",
    "    def fit(self, *args, **kwargs):\n",
    "        if self._was_it_fitted:\n",
    "            return self\n",
    "        else:\n",
    "            super(LoyalCountVectorizer, self).fit(*args, **kwargs)\n",
    "            self._was_it_fitted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParagraphMapper(TransformerMixin):\n",
    "    def __init__(self, paragraphs_mapping):\n",
    "        self.paragraphs_mapping = paragraphs_mapping\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        result = []\n",
    "        for x in X.to_dict(orient='records'):\n",
    "            book_name = x['book_name']\n",
    "            char_1 = x['char_1']\n",
    "            char_2 = x['char_2']\n",
    "            key = f\"{book_name}_{char_1}_{char_2}\"\n",
    "            if key in paragraphs_mapping:\n",
    "                paragraphs = paragraphs_mapping[key]\n",
    "            else:\n",
    "                paragraphs = \"\"\n",
    "            result.append(paragraphs)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(all_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = ParagraphMapper(paragraphs_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "vected = X_train_vect = vectorizer.transform(mapper.transform(X_train_aff))\n",
    "X_test_vect = vectorizer.transform(mapper.transform(X_test_aff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((995, 24082), (995,))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.vstack(X_train_vect).shape, y_train_aff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((995, 24082), (995,))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vected.shape, y_train_aff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(cross_scores):\n",
    "    for mode in ['test', 'train']:\n",
    "        print(f'On {mode} ', end='')\n",
    "        for metric in ['precision', 'recall', 'f1']:\n",
    "            nums = cross_scores[f'{mode}_{metric}_macro']\n",
    "            print(f' avg {metric}: {avg(nums):.2f} ± {np.std(nums):.2f}', end = '')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor mans grid search cv, which I cannot use because of need to fit countvectorizer on whole dataset\n",
    "res = []\n",
    "X = X_train_aff\n",
    "y = y_train_aff.map(score_to_label)\n",
    "paragraph_mapper = ParagraphMapper(paragraphs_mapping)\n",
    "for max_df in np.arange(0.5, 1.0, 0.10):\n",
    "    for min_df in np.arange(0.0, 0.3, 0.05):\n",
    "        vectorizer = CountVectorizer(min_df=min_df,max_df=max_df)\n",
    "        vectorizer.fit(all_paragraphs)\n",
    "        X_vec = vectorizer.transform(paragraph_mapper.transform(X))\n",
    "        for c in np.arange(1.0, 0.1, -0.05):\n",
    "            predictor = LogisticRegression(C=c)\n",
    "            scores = cross_validate(predictor, X_vec, y, scoring=['precision_macro', 'recall_macro', 'f1_macro'], cv=5)\n",
    "            res.append({\n",
    "                **scores,\n",
    "                'max_df': max_df,\n",
    "                'min_df': min_df,\n",
    "                'c': c\n",
    "            })\n",
    "            print(f'max_df={max_df}, min_df={min_df}, c={c}')\n",
    "            report(scores)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)\n",
    "df['test_f1_macro_avg'] = df['test_f1_macro'].apply(lambda x: avg(x))\n",
    "df['test_precision_macro_avg'] = df['test_precision_macro'].apply(lambda x: avg(x))\n",
    "df['test_recall_macro_avg'] = df['test_recall_macro'].apply(lambda x: avg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_precision_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.15000000000000002</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.7999999999999999</th>\n",
       "      <th>test_f1_macro_avg</th>\n",
       "      <th>test_precision_macro_avg</th>\n",
       "      <th>test_recall_macro_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[1.9239139556884766, 1.767948865890503, 1.1202...</td>\n",
       "      <td>[0.004732847213745117, 0.004426240921020508, 0...</td>\n",
       "      <td>[0.39379567154197753, 0.36073313602170426, 0.2...</td>\n",
       "      <td>[0.47922046867527496, 0.4437451437451438, 0.30...</td>\n",
       "      <td>[0.4050747419835334, 0.37751425380591314, 0.31...</td>\n",
       "      <td>[0.7233300810739444, 0.73429347371732, 0.71696...</td>\n",
       "      <td>[0.8972654408297972, 0.8992103108575655, 0.898...</td>\n",
       "      <td>[0.6721192185007974, 0.6834675621860976, 0.665...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352420</td>\n",
       "      <td>0.407043</td>\n",
       "      <td>0.367853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[1.7611210346221924, 1.6658039093017578, 1.135...</td>\n",
       "      <td>[0.0057070255279541016, 0.004531145095825195, ...</td>\n",
       "      <td>[0.39379567154197753, 0.3690474238075714, 0.28...</td>\n",
       "      <td>[0.47922046867527496, 0.44902861366276, 0.2997...</td>\n",
       "      <td>[0.4050747419835334, 0.3838035619820137, 0.312...</td>\n",
       "      <td>[0.7233300810739444, 0.73429347371732, 0.71696...</td>\n",
       "      <td>[0.8972654408297972, 0.8992103108575655, 0.898...</td>\n",
       "      <td>[0.6721192185007974, 0.6834675621860976, 0.665...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351774</td>\n",
       "      <td>0.405775</td>\n",
       "      <td>0.367444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2.2646758556365967, 1.9434220790863037, 1.378...</td>\n",
       "      <td>[0.005259990692138672, 0.004375934600830078, 0...</td>\n",
       "      <td>[0.39379567154197753, 0.3600762205138314, 0.29...</td>\n",
       "      <td>[0.47922046867527496, 0.41692242114237005, 0.3...</td>\n",
       "      <td>[0.4050747419835334, 0.3744577675894904, 0.315...</td>\n",
       "      <td>[0.7216393159084681, 0.7326001080517197, 0.716...</td>\n",
       "      <td>[0.8968497866768047, 0.8987882272765993, 0.898...</td>\n",
       "      <td>[0.670524322169059, 0.6818726658543591, 0.6659...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351560</td>\n",
       "      <td>0.400474</td>\n",
       "      <td>0.366228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.0667049884796143, 1.608933925628662, 1.1960...</td>\n",
       "      <td>[0.005140066146850586, 0.0048999786376953125, ...</td>\n",
       "      <td>[0.39379567154197753, 0.35135151159412564, 0.2...</td>\n",
       "      <td>[0.47922046867527496, 0.4101807121130792, 0.31...</td>\n",
       "      <td>[0.4050747419835334, 0.3692396990536648, 0.315...</td>\n",
       "      <td>[0.7216393159084681, 0.7323003502338272, 0.716...</td>\n",
       "      <td>[0.8968497866768047, 0.8988187523071245, 0.898...</td>\n",
       "      <td>[0.670524322169059, 0.6813971688113565, 0.6659...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351546</td>\n",
       "      <td>0.401793</td>\n",
       "      <td>0.366467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.1497581005096436, 1.8029890060424805, 1.299...</td>\n",
       "      <td>[0.004848957061767578, 0.004930019378662109, 0...</td>\n",
       "      <td>[0.39379567154197753, 0.3513031334555294, 0.29...</td>\n",
       "      <td>[0.47922046867527496, 0.4059022818613611, 0.31...</td>\n",
       "      <td>[0.4050747419835334, 0.36816845941338977, 0.31...</td>\n",
       "      <td>[0.7216393159084681, 0.73429347371732, 0.71696...</td>\n",
       "      <td>[0.8968497866768047, 0.8992103108575655, 0.898...</td>\n",
       "      <td>[0.670524322169059, 0.6834675621860976, 0.6659...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351537</td>\n",
       "      <td>0.400937</td>\n",
       "      <td>0.366252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              fit_time  \\\n",
       "108  [1.9239139556884766, 1.767948865890503, 1.1202...   \n",
       "109  [1.7611210346221924, 1.6658039093017578, 1.135...   \n",
       "5    [2.2646758556365967, 1.9434220790863037, 1.378...   \n",
       "3    [2.0667049884796143, 1.608933925628662, 1.1960...   \n",
       "1    [2.1497581005096436, 1.8029890060424805, 1.299...   \n",
       "\n",
       "                                            score_time  \\\n",
       "108  [0.004732847213745117, 0.004426240921020508, 0...   \n",
       "109  [0.0057070255279541016, 0.004531145095825195, ...   \n",
       "5    [0.005259990692138672, 0.004375934600830078, 0...   \n",
       "3    [0.005140066146850586, 0.0048999786376953125, ...   \n",
       "1    [0.004848957061767578, 0.004930019378662109, 0...   \n",
       "\n",
       "                                         test_f1_macro  \\\n",
       "108  [0.39379567154197753, 0.36073313602170426, 0.2...   \n",
       "109  [0.39379567154197753, 0.3690474238075714, 0.28...   \n",
       "5    [0.39379567154197753, 0.3600762205138314, 0.29...   \n",
       "3    [0.39379567154197753, 0.35135151159412564, 0.2...   \n",
       "1    [0.39379567154197753, 0.3513031334555294, 0.29...   \n",
       "\n",
       "                                  test_precision_macro  \\\n",
       "108  [0.47922046867527496, 0.4437451437451438, 0.30...   \n",
       "109  [0.47922046867527496, 0.44902861366276, 0.2997...   \n",
       "5    [0.47922046867527496, 0.41692242114237005, 0.3...   \n",
       "3    [0.47922046867527496, 0.4101807121130792, 0.31...   \n",
       "1    [0.47922046867527496, 0.4059022818613611, 0.31...   \n",
       "\n",
       "                                     test_recall_macro  \\\n",
       "108  [0.4050747419835334, 0.37751425380591314, 0.31...   \n",
       "109  [0.4050747419835334, 0.3838035619820137, 0.312...   \n",
       "5    [0.4050747419835334, 0.3744577675894904, 0.315...   \n",
       "3    [0.4050747419835334, 0.3692396990536648, 0.315...   \n",
       "1    [0.4050747419835334, 0.36816845941338977, 0.31...   \n",
       "\n",
       "                                        train_f1_macro  \\\n",
       "108  [0.7233300810739444, 0.73429347371732, 0.71696...   \n",
       "109  [0.7233300810739444, 0.73429347371732, 0.71696...   \n",
       "5    [0.7216393159084681, 0.7326001080517197, 0.716...   \n",
       "3    [0.7216393159084681, 0.7323003502338272, 0.716...   \n",
       "1    [0.7216393159084681, 0.73429347371732, 0.71696...   \n",
       "\n",
       "                                 train_precision_macro  \\\n",
       "108  [0.8972654408297972, 0.8992103108575655, 0.898...   \n",
       "109  [0.8972654408297972, 0.8992103108575655, 0.898...   \n",
       "5    [0.8968497866768047, 0.8987882272765993, 0.898...   \n",
       "3    [0.8968497866768047, 0.8988187523071245, 0.898...   \n",
       "1    [0.8968497866768047, 0.8992103108575655, 0.898...   \n",
       "\n",
       "                                    train_recall_macro  0.5  0.0  \\\n",
       "108  [0.6721192185007974, 0.6834675621860976, 0.665...  NaN  0.0   \n",
       "109  [0.6721192185007974, 0.6834675621860976, 0.665...  NaN  0.0   \n",
       "5    [0.670524322169059, 0.6818726658543591, 0.6659...  0.5  0.0   \n",
       "3    [0.670524322169059, 0.6813971688113565, 0.6659...  0.5  0.0   \n",
       "1    [0.670524322169059, 0.6834675621860976, 0.6659...  0.5  0.0   \n",
       "\n",
       "             ...            0.1  0.15000000000000002  0.2  0.25  0.6  0.7  \\\n",
       "108          ...            NaN                  NaN  NaN   NaN  0.6  NaN   \n",
       "109          ...            NaN                  NaN  NaN   NaN  0.6  NaN   \n",
       "5            ...            NaN                  NaN  NaN   NaN  NaN  NaN   \n",
       "3            ...            NaN                  NaN  NaN   NaN  NaN  NaN   \n",
       "1            ...            NaN                  NaN  NaN   NaN  NaN  NaN   \n",
       "\n",
       "     0.7999999999999999  test_f1_macro_avg  test_precision_macro_avg  \\\n",
       "108                 NaN           0.352420                  0.407043   \n",
       "109                 NaN           0.351774                  0.405775   \n",
       "5                   NaN           0.351560                  0.400474   \n",
       "3                   NaN           0.351546                  0.401793   \n",
       "1                   NaN           0.351537                  0.400937   \n",
       "\n",
       "     test_recall_macro_avg  \n",
       "108               0.367853  \n",
       "109               0.367444  \n",
       "5                 0.366228  \n",
       "3                 0.366467  \n",
       "1                 0.366252  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('test_f1_macro_avg', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On test  avg precision: 0.41 ± 0.05 avg recall: 0.37 ± 0.02 avg f1: 0.35 ± 0.03\n",
      "On train  avg precision: 0.90 ± 0.00 avg recall: 0.67 ± 0.01 avg f1: 0.72 ± 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "affinity_pred = LogisticRegression()\n",
    "scores = cross_validate(affinity_pred, X_train_vect, y_train_aff.map(score_to_label), scoring=['precision_macro', 'recall_macro', 'f1_macro'], cv=5)\n",
    "report(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.31      0.15      0.20       262\n",
      "    neutral       0.35      0.16      0.22       201\n",
      "   positive       0.54      0.80      0.64       532\n",
      "\n",
      "avg / total       0.44      0.50      0.44       995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_cv = cross_val_predict(affinity_pred, X_train_vect, y_train_aff.map(score_to_label), cv=5)\n",
    "print(metrics.classification_report(y_train_aff.map(score_to_label), y_predicted_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first results (taking original words, no filtering, taking whole paragraphs)\n",
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   negative       0.27      0.11      0.16       141\n",
    "    neutral       0.30      0.10      0.14       115\n",
    "   positive       0.49      0.83      0.62       235\n",
    "\n",
    "avg / total       0.38      0.45      0.38       491\n",
    "\n",
    "```\n",
    "Compared to baseline (but 'trained' on whole dataset):\n",
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   negative       0.34      0.11      0.17       397\n",
    "    neutral       0.22      0.87      0.36       313\n",
    "   positive       0.61      0.09      0.16       759\n",
    "\n",
    "avg / total       0.46      0.26      0.20      1469\n",
    "```\n",
    "this one actually learns something unlike dummy lookup table which means it at least superior at that. Training performance is way better, and if we compare test performance, well, here we get a smaller precision, but better recall, and overall f1 score is almost twice bigger.\n",
    "And also, I'm going to do cross-validation from this point onwards, to set aside test to use as validation (which I forgot to do earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚫 I initially used tf-idf vectorizers with originalWords, but it yielded way worse results. Assuming this was because unnormalized paragraph length and 'wide' vocabulary. I also tried it with some other cases (the one with stems and non-chars tokens only) with similar level of performance (0.18 ± 0.00 avg recall: 0.33 ± 0.00 avg f1: 0.23 ± 0.00 - and ony predicting positive for test set)\n",
    "\n",
    "**Taking lemmas** yields following results on cross_validation & report from cross_predict:\n",
    "``` \n",
    "On test  avg precision: 0.40 ± 0.06 avg recall: 0.36 ± 0.04 avg f1: 0.35 ± 0.04\n",
    "On train  avg precision: 0.90 ± 0.00 avg recall: 0.68 ± 0.01 avg f1: 0.73 ± 0.01\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   negative       0.35      0.16      0.22       262\n",
    "    neutral       0.30      0.15      0.20       201\n",
    "   positive       0.53      0.78      0.63       532\n",
    "\n",
    "avg / total       0.44      0.49      0.44       995\n",
    "```\n",
    "✅ This one is better on both precision and recall.\n",
    "\n",
    "Following step: **use stemms**\n",
    "```\n",
    "On test  avg precision: 0.41 ± 0.06 avg recall: 0.37 ± 0.04 avg f1: 0.36 ± 0.04\n",
    "On train  avg precision: 0.90 ± 0.00 avg recall: 0.68 ± 0.01 avg f1: 0.73 ± 0.01\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   negative       0.36      0.16      0.23       262\n",
    "    neutral       0.33      0.16      0.22       201\n",
    "   positive       0.54      0.79      0.64       532\n",
    "\n",
    "avg / total       0.45      0.50      0.45       995\n",
    "```\n",
    "✅ Slightly better. Assumption here was that reducing feature space + same stems yielding similar concepts might imrpove model.\n",
    "\n",
    "Following step: **keep non-chars tokens only**\n",
    "\n",
    "If I remove char tokens I'll get:\n",
    "```\n",
    "On test  avg precision: 0.41 ± 0.03 avg recall: 0.37 ± 0.02 avg f1: 0.36 ± 0.03\n",
    "On train  avg precision: 0.90 ± 0.00 avg recall: 0.68 ± 0.01 avg f1: 0.73 ± 0.01\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   negative       0.34      0.16      0.21       262\n",
    "    neutral       0.34      0.15      0.21       201\n",
    "   positive       0.54      0.80      0.65       532\n",
    "\n",
    "avg / total       0.45      0.50      0.44       995\n",
    "\n",
    "```\n",
    "❓seems to have smaller std on test. But also, we see that positive class seems to work better, yet negative / neutral slightly degenerates.\n",
    "Hypotheses here (compared to previous values):\n",
    "\n",
    "1. we were overfitting on character to predict relations\n",
    "2. character stem was indicative of what type of relations there might be\n",
    "\n",
    "First one would be mitigated by limiting dictionary size, ensuring we only get frequent enough words (although it might be that all the Bills across all the books are almost always evil or something)\n",
    "\n",
    "🚫 Following step: **keep tokens BETWEEN characters only +- some window **\n",
    "\n",
    "Initial try yielded worse results (pr - 0.40, re - 0.48, f1 - 0.41), which might be caused by issue in implementation or the fact that characters are mismatching and multiple bookNLP represent single character, yet we are unknowingly throw away that data. Updating max-distance param to 45 didn't improve the result compared to previous steps (pr - 0.39, re - 0.46, f1 - 0.40), yet pruning extra words and throwing away looong paragraphs that are talking about every possible character in the book should improve (I guess) our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to **tune CountVectorizer's and LogReg parameters**  \n",
    "🚫 Okay, running some grid search resulted in way worse results that those without any tuning. This might be\n",
    "\n",
    "1. due to signal being wide spread and maxdf/mindf being too restrictive and cutting vocabulary word inclusions too hight or too low (meaning average widespread words are non-indicative)\n",
    "2. bag of word capturing stylistic things of authors writing (not sure this would be messing up results that bad)\n",
    "3. we are actually already overfit on testing\n",
    "\n",
    "I assume that's it for this model on this level of data cleanliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW + kNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_aff\n",
    "y = y_train_aff.map(score_to_label)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(all_paragraphs)\n",
    "X_vec = vectorizer.transform(paragraph_mapper.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    'negative': 'red',\n",
    "    'neutral': 'yellow',\n",
    "    'positive': 'green'\n",
    "}\n",
    "colors = y.map(lambda val: col_map[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 995 samples in 0.561s...\n",
      "[t-SNE] Computed neighbors for 995 samples in 18.167s...\n",
      "[t-SNE] Computed conditional probabilities for sample 995 / 995\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 60.558315\n",
      "[t-SNE] Error after 300 iterations: 0.743109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bb299c88>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEyCAYAAACbGke8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL8PWzqyt+FrzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bab89eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X_vec.toarray())\n",
    "\n",
    "# plot the result\n",
    "vis_x = tsne_results[:, 0]\n",
    "vis_y = tsne_results[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(vis_x, vis_y, c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 3 (uniform)\n",
      "On test  avg precision: 0.32 ± 0.04 avg recall: 0.36 ± 0.03 avg f1: 0.30 ± 0.02\n",
      "On train  avg precision: 0.61 ± 0.02 avg recall: 0.48 ± 0.01 avg f1: 0.44 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.29      0.67      0.40       262\n",
      "    neutral       0.07      0.01      0.02       201\n",
      "   positive       0.60      0.39      0.47       532\n",
      "\n",
      "avg / total       0.41      0.39      0.36       995\n",
      "\n",
      "N: 3 (distance)\n",
      "On test  avg precision: 0.33 ± 0.04 avg recall: 0.35 ± 0.02 avg f1: 0.31 ± 0.03\n",
      "On train  avg precision: 0.82 ± 0.00 avg recall: 0.71 ± 0.01 avg f1: 0.69 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.29      0.62      0.40       262\n",
      "    neutral       0.12      0.04      0.06       201\n",
      "   positive       0.57      0.40      0.47       532\n",
      "\n",
      "avg / total       0.41      0.39      0.37       995\n",
      "\n",
      "N: 4 (uniform)\n",
      "On test  avg precision: 0.34 ± 0.03 avg recall: 0.33 ± 0.02 avg f1: 0.30 ± 0.02\n",
      "On train  avg precision: 0.56 ± 0.03 avg recall: 0.46 ± 0.02 avg f1: 0.45 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.27      0.30      0.28       262\n",
      "    neutral       0.18      0.06      0.10       201\n",
      "   positive       0.54      0.64      0.59       532\n",
      "\n",
      "avg / total       0.40      0.43      0.41       995\n",
      "\n",
      "N: 4 (distance)\n",
      "On test  avg precision: 0.35 ± 0.05 avg recall: 0.35 ± 0.03 avg f1: 0.31 ± 0.03\n",
      "On train  avg precision: 0.86 ± 0.04 avg recall: 0.69 ± 0.02 avg f1: 0.71 ± 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.28      0.28      0.28       262\n",
      "    neutral       0.20      0.06      0.09       201\n",
      "   positive       0.55      0.69      0.61       532\n",
      "\n",
      "avg / total       0.41      0.46      0.42       995\n",
      "\n",
      "N: 5 (uniform)\n",
      "On test  avg precision: 0.35 ± 0.05 avg recall: 0.35 ± 0.03 avg f1: 0.31 ± 0.03\n",
      "On train  avg precision: 0.53 ± 0.02 avg recall: 0.45 ± 0.02 avg f1: 0.43 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.27      0.30      0.29       262\n",
      "    neutral       0.22      0.08      0.12       201\n",
      "   positive       0.55      0.65      0.60       532\n",
      "\n",
      "avg / total       0.41      0.45      0.42       995\n",
      "\n",
      "N: 5 (distance)\n",
      "On test  avg precision: 0.34 ± 0.07 avg recall: 0.34 ± 0.04 avg f1: 0.30 ± 0.04\n",
      "On train  avg precision: 0.86 ± 0.04 avg recall: 0.69 ± 0.02 avg f1: 0.71 ± 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.28      0.28      0.28       262\n",
      "    neutral       0.18      0.04      0.07       201\n",
      "   positive       0.55      0.70      0.61       532\n",
      "\n",
      "avg / total       0.40      0.46      0.42       995\n",
      "\n",
      "N: 6 (uniform)\n",
      "On test  avg precision: 0.34 ± 0.04 avg recall: 0.34 ± 0.01 avg f1: 0.29 ± 0.02\n",
      "On train  avg precision: 0.53 ± 0.02 avg recall: 0.42 ± 0.02 avg f1: 0.40 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.27      0.22      0.24       262\n",
      "    neutral       0.22      0.04      0.07       201\n",
      "   positive       0.54      0.75      0.62       532\n",
      "\n",
      "avg / total       0.40      0.47      0.41       995\n",
      "\n",
      "N: 6 (distance)\n",
      "On test  avg precision: 0.34 ± 0.02 avg recall: 0.34 ± 0.00 avg f1: 0.29 ± 0.01\n",
      "On train  avg precision: 0.88 ± 0.03 avg recall: 0.68 ± 0.02 avg f1: 0.72 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.28      0.19      0.23       262\n",
      "    neutral       0.19      0.04      0.07       201\n",
      "   positive       0.54      0.78      0.63       532\n",
      "\n",
      "avg / total       0.40      0.47      0.41       995\n",
      "\n",
      "N: 7 (uniform)\n",
      "On test  avg precision: 0.32 ± 0.05 avg recall: 0.35 ± 0.03 avg f1: 0.30 ± 0.03\n",
      "On train  avg precision: 0.49 ± 0.02 avg recall: 0.42 ± 0.02 avg f1: 0.39 ± 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.29      0.42      0.34       262\n",
      "    neutral       0.16      0.04      0.07       201\n",
      "   positive       0.55      0.58      0.56       532\n",
      "\n",
      "avg / total       0.40      0.43      0.41       995\n",
      "\n",
      "N: 7 (distance)\n",
      "On test  avg precision: 0.33 ± 0.05 avg recall: 0.35 ± 0.03 avg f1: 0.31 ± 0.03\n",
      "On train  avg precision: 0.85 ± 0.04 avg recall: 0.69 ± 0.02 avg f1: 0.70 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.30      0.40      0.34       262\n",
      "    neutral       0.16      0.04      0.06       201\n",
      "   positive       0.56      0.62      0.59       532\n",
      "\n",
      "avg / total       0.41      0.45      0.42       995\n",
      "\n",
      "N: 8 (uniform)\n",
      "On test  avg precision: 0.31 ± 0.02 avg recall: 0.34 ± 0.02 avg f1: 0.29 ± 0.02\n",
      "On train  avg precision: 0.49 ± 0.03 avg recall: 0.41 ± 0.02 avg f1: 0.38 ± 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.29      0.40      0.33       262\n",
      "    neutral       0.13      0.03      0.06       201\n",
      "   positive       0.54      0.59      0.56       532\n",
      "\n",
      "avg / total       0.39      0.43      0.40       995\n",
      "\n",
      "N: 8 (distance)\n",
      "On test  avg precision: 0.31 ± 0.04 avg recall: 0.35 ± 0.03 avg f1: 0.29 ± 0.04\n",
      "On train  avg precision: 0.85 ± 0.04 avg recall: 0.69 ± 0.02 avg f1: 0.70 ± 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.30      0.39      0.33       262\n",
      "    neutral       0.11      0.02      0.03       201\n",
      "   positive       0.55      0.63      0.59       532\n",
      "\n",
      "avg / total       0.39      0.44      0.41       995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_neighbors in range(3, 9):\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        print(f'N: {n_neighbors} ({weights})')\n",
    "        affinity_pred = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "        scores = cross_validate(affinity_pred, X_vec, y_train_aff.map(score_to_label), scoring=['precision_macro', 'recall_macro', 'f1_macro'], cv=5, return_train_score=True)\n",
    "        report(scores)\n",
    "        y_predicted_cv = cross_val_predict(affinity_pred, X_vec, y_train_aff.map(score_to_label), cv=5)\n",
    "        print(metrics.classification_report(y_train_aff.map(score_to_label), y_predicted_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to be imrpove over LogReg, consistently worse performance, which kinda might indicate initial BoW model is not actually representing trends in input data / we are missing quite a lot of chars / each relations is a unique snowflake and uses all the different words every time.\n",
    "\n",
    "Okay, so personal best is LogReg, BoW on stems for words in paragraphs, in which both of characters were mentioned. Let's run this on test set for 'best' kNN (just seemed to be good enough + performance on 'neutral' is not that bad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.30      0.63      0.40       141\n",
      "    neutral       0.33      0.05      0.09       115\n",
      "   positive       0.50      0.37      0.43       235\n",
      "\n",
      "avg / total       0.40      0.37      0.34       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=6)\n",
    "kNN.fit(X_train_vect, y_train_aff.map(score_to_label))\n",
    "y_predicted = kNN.predict(X_test_vect)\n",
    "print(metrics.classification_report(y_test_aff.map(score_to_label), y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.28      0.11      0.15       141\n",
      "    neutral       0.33      0.13      0.19       115\n",
      "   positive       0.49      0.81      0.61       235\n",
      "\n",
      "avg / total       0.39      0.45      0.38       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_LogReg = LogisticRegression()\n",
    "BoW_LogReg.fit(X_train_vect, y_train_aff.map(score_to_label))\n",
    "y_predicted = BoW_LogReg.predict(X_test_vect)\n",
    "print(metrics.classification_report(y_test_aff.map(score_to_label), y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VS Baselines:  \n",
    "```avg / total       0.46      0.26      0.20      1469```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, seems that test performance is 0.05-0.1 worse that CV one. But they are better than baseline's performance.\n",
    "\n",
    "That's all folks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
